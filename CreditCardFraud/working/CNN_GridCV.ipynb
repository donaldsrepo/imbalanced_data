{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having trouble getting the gridcv to work with an AI model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import Libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas_profiling as pp\n",
    "import seaborn as sns\n",
    "import os\n",
    "import time\n",
    "import zipfile\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import MaxPool1D\n",
    "from keras.layers import Flatten\n",
    "#from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras import regularizers\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import Adagrad\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "colab = os.environ.get('COLAB_GPU', '10')\n",
    "if (int(colab) == 0):\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    #Path=\"drive/My Drive/Colab Notebooks/StockAnalysis\"\n",
    "    Path=\"\" # ???\n",
    "    DataPath=\"/content\"\n",
    "    RootPath=\"/root\"    \n",
    "else:\n",
    "    #Path=\"/c/DataScience/Repo/Imbalanced_data\"\n",
    "    Path=\"/DataScience/Repo/Imbalanced_data\"\n",
    "    DataPath=Path\n",
    "    RootPath=\"/Users/iowahawk89\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Data Set\n",
    "df = pd.read_csv('https://storage.googleapis.com/download.tensorflow.org/data/creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.loc[:, df.columns != 'Class']\n",
    "y = df.loc[:, df.columns == 'Class']\n",
    "X_train, X_test1, y_train, y_test1 = train_test_split(X,y, test_size = 0.4, random_state = 42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test1,y_test1, test_size = 0.4, random_state = 42)\n",
    "class_names=[0,1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downsampling\n",
    "yes = len(y_train[y_train['Class'] ==1]) \n",
    "yes_ind = y_train[y_train['Class'] == 1].index\n",
    "no_ind = y_train[y_train['Class'] == 0].index\n",
    "new_no_ind = np.random.choice(no_ind, yes, replace = False)\n",
    "undersample_ind = np.concatenate([new_no_ind, yes_ind])\n",
    "X_train = X_train.loc[undersample_ind]\n",
    "y_train = y_train.loc[undersample_ind]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTimer():\n",
    "    def __init__(self):\n",
    "        self.start = time.time()\n",
    "    def __enter__(self):\n",
    "        return self\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        end = time.time()\n",
    "        runtime = end - self.start\n",
    "        msg = 'The function took {time} seconds to complete'\n",
    "        print(msg.format(time=runtime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_metrics(model_name, train_features, test_features, train_label, test_label, pred):\n",
    "    try:\n",
    "        print(model_name.score(test_features, test_label)) \n",
    "        print(\"Accuracy score (training): {0:.3f}\".format(model_name.score(train_features, train_label))) \n",
    "        print(\"Accuracy score (validation): {0:.3f}\".format(model_name.score(test_features, test_label))) \n",
    "    except Exception as e:\n",
    "        print(\"error\")  \n",
    "    try:\n",
    "        print(pd.Series(model_name.feature_importances_, index=train_features.columns[:]).nlargest(10).plot(kind='barh')) \n",
    "    except Exception as e:\n",
    "        print(\"error\")  \n",
    "\n",
    "    print(\"Confusion Matrix:\")\n",
    "    tn, fp, fn, tp = confusion_matrix(test_label, pred).ravel()\n",
    "    total = tn+ fp+ fn+ tp \n",
    "    print(\"false positive pct:\",(fp/total)*100) \n",
    "    print(\"tn\", \" fp\", \" fn\", \" tp\") \n",
    "    print(tn, fp, fn, tp) \n",
    "    print(confusion_matrix(test_label, pred)) \n",
    "    print(\"Classification Report\") \n",
    "    print(classification_report(test_label, pred))\n",
    "    print(\"Specificity =\", tn/(tn+fp))\n",
    "    print(\"Sensitivity =\", tp/(tp+fn))\n",
    "    return tn, fp, fn, tp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>154340</th>\n",
       "      <td>101231.0</td>\n",
       "      <td>1.801432</td>\n",
       "      <td>-0.280307</td>\n",
       "      <td>-0.706453</td>\n",
       "      <td>1.409947</td>\n",
       "      <td>0.442907</td>\n",
       "      <td>1.067900</td>\n",
       "      <td>-0.323879</td>\n",
       "      <td>0.114636</td>\n",
       "      <td>2.047498</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025988</td>\n",
       "      <td>-0.617295</td>\n",
       "      <td>-1.416970</td>\n",
       "      <td>0.283564</td>\n",
       "      <td>-0.316434</td>\n",
       "      <td>-0.237016</td>\n",
       "      <td>-1.150447</td>\n",
       "      <td>0.014197</td>\n",
       "      <td>-0.032308</td>\n",
       "      <td>89.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29392</th>\n",
       "      <td>35453.0</td>\n",
       "      <td>1.094547</td>\n",
       "      <td>-0.039137</td>\n",
       "      <td>1.404872</td>\n",
       "      <td>1.272242</td>\n",
       "      <td>-0.980858</td>\n",
       "      <td>0.012955</td>\n",
       "      <td>-0.620778</td>\n",
       "      <td>0.192990</td>\n",
       "      <td>0.537514</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.094773</td>\n",
       "      <td>0.009329</td>\n",
       "      <td>0.221075</td>\n",
       "      <td>0.001036</td>\n",
       "      <td>0.547954</td>\n",
       "      <td>0.374995</td>\n",
       "      <td>-0.440598</td>\n",
       "      <td>0.072374</td>\n",
       "      <td>0.031356</td>\n",
       "      <td>9.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158679</th>\n",
       "      <td>111638.0</td>\n",
       "      <td>2.031383</td>\n",
       "      <td>-0.116482</td>\n",
       "      <td>-3.184738</td>\n",
       "      <td>-0.604844</td>\n",
       "      <td>2.687599</td>\n",
       "      <td>3.010431</td>\n",
       "      <td>-0.373632</td>\n",
       "      <td>0.723440</td>\n",
       "      <td>0.439272</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.116474</td>\n",
       "      <td>0.196974</td>\n",
       "      <td>0.608777</td>\n",
       "      <td>0.013515</td>\n",
       "      <td>0.637164</td>\n",
       "      <td>0.286998</td>\n",
       "      <td>-0.081198</td>\n",
       "      <td>0.015391</td>\n",
       "      <td>-0.036639</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163866</th>\n",
       "      <td>116260.0</td>\n",
       "      <td>-0.429972</td>\n",
       "      <td>1.253972</td>\n",
       "      <td>-2.038432</td>\n",
       "      <td>-1.450138</td>\n",
       "      <td>3.756487</td>\n",
       "      <td>2.879112</td>\n",
       "      <td>0.638268</td>\n",
       "      <td>0.773257</td>\n",
       "      <td>-0.469925</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002523</td>\n",
       "      <td>0.198471</td>\n",
       "      <td>0.495190</td>\n",
       "      <td>-0.407864</td>\n",
       "      <td>0.484234</td>\n",
       "      <td>0.162100</td>\n",
       "      <td>-0.126988</td>\n",
       "      <td>0.042217</td>\n",
       "      <td>0.216694</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65917</th>\n",
       "      <td>51803.0</td>\n",
       "      <td>-1.647527</td>\n",
       "      <td>1.093779</td>\n",
       "      <td>0.955744</td>\n",
       "      <td>1.578528</td>\n",
       "      <td>-0.407383</td>\n",
       "      <td>-0.215360</td>\n",
       "      <td>0.054097</td>\n",
       "      <td>0.783982</td>\n",
       "      <td>-0.944366</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.168710</td>\n",
       "      <td>0.108617</td>\n",
       "      <td>0.336914</td>\n",
       "      <td>0.096226</td>\n",
       "      <td>0.463624</td>\n",
       "      <td>0.199963</td>\n",
       "      <td>-0.217167</td>\n",
       "      <td>-0.130682</td>\n",
       "      <td>-0.190706</td>\n",
       "      <td>23.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42674</th>\n",
       "      <td>41194.0</td>\n",
       "      <td>-7.896886</td>\n",
       "      <td>5.381020</td>\n",
       "      <td>-8.451162</td>\n",
       "      <td>7.963928</td>\n",
       "      <td>-7.862419</td>\n",
       "      <td>-2.376820</td>\n",
       "      <td>-11.949723</td>\n",
       "      <td>5.051356</td>\n",
       "      <td>-6.912076</td>\n",
       "      <td>...</td>\n",
       "      <td>0.645974</td>\n",
       "      <td>2.557944</td>\n",
       "      <td>0.926278</td>\n",
       "      <td>0.032795</td>\n",
       "      <td>0.638073</td>\n",
       "      <td>0.361887</td>\n",
       "      <td>0.444577</td>\n",
       "      <td>1.101923</td>\n",
       "      <td>0.205958</td>\n",
       "      <td>1.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33276</th>\n",
       "      <td>37167.0</td>\n",
       "      <td>-7.923891</td>\n",
       "      <td>-5.198360</td>\n",
       "      <td>-3.000024</td>\n",
       "      <td>4.420666</td>\n",
       "      <td>2.272194</td>\n",
       "      <td>-3.394483</td>\n",
       "      <td>-5.283435</td>\n",
       "      <td>0.131619</td>\n",
       "      <td>0.658176</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.169811</td>\n",
       "      <td>-0.734308</td>\n",
       "      <td>-0.599926</td>\n",
       "      <td>-4.908301</td>\n",
       "      <td>0.410170</td>\n",
       "      <td>-1.167660</td>\n",
       "      <td>0.520508</td>\n",
       "      <td>1.937421</td>\n",
       "      <td>-1.552593</td>\n",
       "      <td>12.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182992</th>\n",
       "      <td>125612.0</td>\n",
       "      <td>1.889618</td>\n",
       "      <td>1.073099</td>\n",
       "      <td>-1.678018</td>\n",
       "      <td>4.173268</td>\n",
       "      <td>1.015516</td>\n",
       "      <td>-0.009389</td>\n",
       "      <td>-0.079706</td>\n",
       "      <td>0.064071</td>\n",
       "      <td>-0.714517</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.153570</td>\n",
       "      <td>0.203728</td>\n",
       "      <td>0.733796</td>\n",
       "      <td>-0.036560</td>\n",
       "      <td>0.334306</td>\n",
       "      <td>0.147171</td>\n",
       "      <td>0.279556</td>\n",
       "      <td>0.031669</td>\n",
       "      <td>0.035883</td>\n",
       "      <td>3.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154697</th>\n",
       "      <td>102625.0</td>\n",
       "      <td>-4.221221</td>\n",
       "      <td>2.871121</td>\n",
       "      <td>-5.888716</td>\n",
       "      <td>6.890952</td>\n",
       "      <td>-3.404894</td>\n",
       "      <td>-1.154394</td>\n",
       "      <td>-7.739928</td>\n",
       "      <td>2.851363</td>\n",
       "      <td>-2.507569</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.227882</td>\n",
       "      <td>1.620591</td>\n",
       "      <td>1.567947</td>\n",
       "      <td>-0.578007</td>\n",
       "      <td>-0.059045</td>\n",
       "      <td>-1.829169</td>\n",
       "      <td>-0.072429</td>\n",
       "      <td>0.136734</td>\n",
       "      <td>-0.599848</td>\n",
       "      <td>7.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226814</th>\n",
       "      <td>144808.0</td>\n",
       "      <td>-2.405207</td>\n",
       "      <td>2.943823</td>\n",
       "      <td>-7.616654</td>\n",
       "      <td>3.533374</td>\n",
       "      <td>-5.417494</td>\n",
       "      <td>-0.112632</td>\n",
       "      <td>-1.329372</td>\n",
       "      <td>1.709417</td>\n",
       "      <td>-2.322716</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.338707</td>\n",
       "      <td>0.652683</td>\n",
       "      <td>0.414132</td>\n",
       "      <td>0.023869</td>\n",
       "      <td>-0.260616</td>\n",
       "      <td>0.405316</td>\n",
       "      <td>0.029107</td>\n",
       "      <td>0.519807</td>\n",
       "      <td>-0.469537</td>\n",
       "      <td>667.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>602 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "154340  101231.0  1.801432 -0.280307 -0.706453  1.409947  0.442907  1.067900   \n",
       "29392    35453.0  1.094547 -0.039137  1.404872  1.272242 -0.980858  0.012955   \n",
       "158679  111638.0  2.031383 -0.116482 -3.184738 -0.604844  2.687599  3.010431   \n",
       "163866  116260.0 -0.429972  1.253972 -2.038432 -1.450138  3.756487  2.879112   \n",
       "65917    51803.0 -1.647527  1.093779  0.955744  1.578528 -0.407383 -0.215360   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "42674    41194.0 -7.896886  5.381020 -8.451162  7.963928 -7.862419 -2.376820   \n",
       "33276    37167.0 -7.923891 -5.198360 -3.000024  4.420666  2.272194 -3.394483   \n",
       "182992  125612.0  1.889618  1.073099 -1.678018  4.173268  1.015516 -0.009389   \n",
       "154697  102625.0 -4.221221  2.871121 -5.888716  6.890952 -3.404894 -1.154394   \n",
       "226814  144808.0 -2.405207  2.943823 -7.616654  3.533374 -5.417494 -0.112632   \n",
       "\n",
       "               V7        V8        V9  ...       V20       V21       V22  \\\n",
       "154340  -0.323879  0.114636  2.047498  ... -0.025988 -0.617295 -1.416970   \n",
       "29392   -0.620778  0.192990  0.537514  ... -0.094773  0.009329  0.221075   \n",
       "158679  -0.373632  0.723440  0.439272  ... -0.116474  0.196974  0.608777   \n",
       "163866   0.638268  0.773257 -0.469925  ... -0.002523  0.198471  0.495190   \n",
       "65917    0.054097  0.783982 -0.944366  ... -0.168710  0.108617  0.336914   \n",
       "...           ...       ...       ...  ...       ...       ...       ...   \n",
       "42674  -11.949723  5.051356 -6.912076  ...  0.645974  2.557944  0.926278   \n",
       "33276   -5.283435  0.131619  0.658176  ... -2.169811 -0.734308 -0.599926   \n",
       "182992  -0.079706  0.064071 -0.714517  ... -0.153570  0.203728  0.733796   \n",
       "154697  -7.739928  2.851363 -2.507569  ... -0.227882  1.620591  1.567947   \n",
       "226814  -1.329372  1.709417 -2.322716  ... -0.338707  0.652683  0.414132   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28  Amount  \n",
       "154340  0.283564 -0.316434 -0.237016 -1.150447  0.014197 -0.032308   89.25  \n",
       "29392   0.001036  0.547954  0.374995 -0.440598  0.072374  0.031356    9.99  \n",
       "158679  0.013515  0.637164  0.286998 -0.081198  0.015391 -0.036639   10.00  \n",
       "163866 -0.407864  0.484234  0.162100 -0.126988  0.042217  0.216694    1.00  \n",
       "65917   0.096226  0.463624  0.199963 -0.217167 -0.130682 -0.190706   23.52  \n",
       "...          ...       ...       ...       ...       ...       ...     ...  \n",
       "42674   0.032795  0.638073  0.361887  0.444577  1.101923  0.205958    1.52  \n",
       "33276  -4.908301  0.410170 -1.167660  0.520508  1.937421 -1.552593   12.31  \n",
       "182992 -0.036560  0.334306  0.147171  0.279556  0.031669  0.035883    3.22  \n",
       "154697 -0.578007 -0.059045 -1.829169 -0.072429  0.136734 -0.599848    7.59  \n",
       "226814  0.023869 -0.260616  0.405316  0.029107  0.519807 -0.469537  667.55  \n",
       "\n",
       "[602 rows x 30 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows, ncols = X_train.shape # (602,30)\n",
    "X_train_arr = X_train.to_numpy()\n",
    "y_train_arr = y_train.to_numpy()\n",
    "X_train_arr = X_train_arr.reshape(nrows, ncols, 1)\n",
    "\n",
    "nrows, ncols = X_test.shape # (602,30)\n",
    "X_test_arr = X_test.to_numpy()\n",
    "y_test_arr = y_test.to_numpy()\n",
    "X_test_arr = X_test_arr.reshape(nrows, ncols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 1)\n"
     ]
    }
   ],
   "source": [
    "input_shape = (ncols, 1)\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.backend import sigmoid\n",
    "def swish(x, beta = 1):\n",
    "    return (x * sigmoid(beta * x))\n",
    "\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras.layers import Activation\n",
    "get_custom_objects().update({'swish': Activation(swish)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a 1D Convolution, which is useful for non-image data, such as time series related data (audio, sensor)\n",
    "Be sure to remember to include an activation function in the initial Conv1D layer, otherwise the model will predict all minority case of 1's (FP rate is almost 100%) !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_model():\n",
    "    model = Sequential()\n",
    "    #model.add(Conv1D(32, 2, activation = 'relu', input_shape = input_shape))\n",
    "    #model.add(Conv1D(filters=32, kernel_size=2, input_shape = (30) ))\n",
    "    model.add(Conv1D(filters=32, kernel_size=10, strides=1, activation='swish', padding='valid', input_shape=input_shape ))\n",
    "    # TypeError: 'int' object is not iterable\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPool1D(2))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv1D(64, 2, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPool1D(2))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    #model.compile(optimizer='adam', lr=0.001, loss = 'binary_crossentropy', metrics=['accuracy'])\n",
    "    # or\n",
    "    #opt = keras.optimizers.RMSprop(learning_rate=0.0001, decay=1e-6)\n",
    "    # Let's train the model using RMSprop\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  #optimizer=opt,\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def create_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(12, input_dim=30, activation='relu'))\n",
    "\tmodel.add(Dense(1, activation='sigmoid'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "602/602 [==============================] - 0s 464us/step - loss: 6230.0187 - accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "compiled_model = create_model()\n",
    "\n",
    "compiled_model.fit(X_train, y_train)\n",
    "\n",
    "model = KerasClassifier(build_fn=compiled_model, verbose=0)\n",
    "#print(compiled_model.summary())\n",
    "#model.fit(X_train, y_train)\n",
    "\n",
    "X_train = X_train_arr.copy()\n",
    "y_train = y_train_arr.copy()\n",
    "\n",
    "gsc = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid={\n",
    "        #'n_estimators': range(50,126,25),\n",
    "        'epochs':[50,100]\n",
    "        #'max_features': range(50,401,50),\n",
    "        #'max_features': [50,100], # can be list or range or other\n",
    "        #'criterion':['mse','mae']\n",
    "        #min_samples_leaf': range(20,50,5),\n",
    "        #min_samples_split': range(15,36,5),\n",
    "    },\n",
    "    scoring='roc_auc',\n",
    "    #scoring='neg_mean_squared_error', # or look here for other choices \n",
    "    # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "    cv=5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\iowahawk89\\miniconda3\\envs\\ds_tensorflow\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: __call__() missing 1 required positional argument: 'inputs'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The function took 9.341293573379517 seconds to complete\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__call__() missing 1 required positional argument: 'inputs'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-22c054785277>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Running GridSearchCV:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mMyTimer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mgrid_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgsc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Best: %f using %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mgrid_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrid_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\ds_tensorflow\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    737\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 739\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    740\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    741\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\ds_tensorflow\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, sample_weight, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sample_weight'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\ds_tensorflow\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m               not isinstance(self.build_fn, types.MethodType)):\n\u001b[0;32m    139\u001b[0m             self.model = self.build_fn(\n\u001b[1;32m--> 140\u001b[1;33m                 **self.filter_sk_params(self.build_fn.__call__))\n\u001b[0m\u001b[0;32m    141\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter_sk_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\ds_tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36msymbolic_fn_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_SYMBOLIC_SCOPE\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __call__() missing 1 required positional argument: 'inputs'"
     ]
    }
   ],
   "source": [
    "#model.fit(X_train, y_train)\n",
    "print(\"Running GridSearchCV:\")\n",
    "with MyTimer():    \n",
    "    grid_result = gsc.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "#for test_mean, train_mean, param in zip(\n",
    "for test_mean, param in zip(\n",
    "        grid_result.cv_results_['mean_test_score'],\n",
    "        #grid_result.cv_results_['mean_train_score'],\n",
    "        grid_result.cv_results_['params']):\n",
    "    print(\"Test : %f with: %r\" % (test_mean, param))\n",
    "    \n",
    "#model = ExtraTreesRegressor(**grid_result.best_params_)\n",
    "model = Sequential(**grid_result.best_params_)\n",
    "\n",
    "print(\"Fitting Model with GridSearch and Cross Validation:\")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(model.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200 # maybe 200?\n",
    "model = create_model()\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "#class_weight = {1: 0.75,\n",
    "#                0: 0.25}\n",
    "with MyTimer():\n",
    "\n",
    "    #history = model.fit(X_train_arr, y_train_arr, epochs=epochs, validation_data=(X_test, y_test), verbose=1)\n",
    "    history = model.fit(X_train_arr, y_train_arr, epochs=epochs, verbose=1, sample_weight=np.where(y_train_arr == 1,6.0,1.0).flatten())\n",
    "    #history = model.fit(X_train_arr, y_train_arr, epochs=epochs, verbose=1, sample_weight=class_weight)\n",
    "#plot_learningCurve(history, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict probabilities for test set\n",
    "yhat_probs = model.predict(X_test_arr, verbose=0)\n",
    "# predict crisp classes for test set\n",
    "yhat_classes = model.predict_classes(X_test_arr, verbose=0)\n",
    "# reduce to 1d array\n",
    "yhat_probs = yhat_probs[:, 0]\n",
    "yhat_classes = yhat_classes[:, 0]\n",
    "\n",
    "tn, fp, fn, tp = display_metrics(model, X_train_arr, X_test_arr, y_train_arr, y_test_arr, yhat_classes)\n",
    "#visualize(y_test_arr, yhat_classes, 'CNN Simple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(y_test_arr, yhat_classes, pos_label=1)\n",
    "print('TEST | AUC Score: ' + str((metrics.auc(fpr, tpr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use scikit-learn to grid search the batch size and epochs\n",
    "import numpy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# load dataset\n",
    "dataset = numpy.loadtxt(\"http://nrvis.com/data/mldata/pima-indians-diabetes.csv\", delimiter=\",\")\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "# define the grid search parameters\n",
    "batch_size = [10, 20, 40, 60, 80, 100]\n",
    "epochs = [10, 50, 100]\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X, Y)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
